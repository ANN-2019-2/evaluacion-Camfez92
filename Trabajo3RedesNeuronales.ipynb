{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Trabajo3RedesNeuronales.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4ALw5t_QaZC",
        "colab_type": "text"
      },
      "source": [
        "Se cargan las líbrerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xonz_6-EKhOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import sklearn.neural_network\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieQPoYqSQgl5",
        "colab_type": "text"
      },
      "source": [
        "Se cargan los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4Si2j41OIQc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/jdvelasq/datalabs/master/datasets/sms-spam.csv\",\n",
        "    sep = ',',\n",
        "    thousands = None,\n",
        "    decimal = '.',\n",
        "    encoding='latin-1')\n",
        "data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gr9gf1XTiMhB",
        "colab_type": "text"
      },
      "source": [
        "Creamos una copia de los datos (mails) para operar sobre ella y luego eliminamos los afijos morfológicos de las palabras, dejando únicamente su raíz; ésto lo agregamos a una nueva columna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKhnSggVRfJx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "outputId": "3e1ebdec-68cc-4870-85ab-64daa65f9d82"
      },
      "source": [
        "mails=data.copy()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "mails['stemmed'] = mails.text.apply(lambda x: ' '.join([stemmer.stem(w) for w in x.split() ]))\n",
        "\n",
        "mails.head(10)\n",
        "\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>text</th>\n",
              "      <th>stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>Go until jurong point, crazy.. avail onli in b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>Ok lar... joke wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entri in 2 a wkli comp to win FA cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>U dun say so earli hor... U c alreadi then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>nah I don't think he goe to usf, he live aroun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>spam</td>\n",
              "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
              "      <td>freemsg hey there darl it' been 3 week' now an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ham</td>\n",
              "      <td>Even my brother is not like to speak with me. ...</td>\n",
              "      <td>even my brother is not like to speak with me. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ham</td>\n",
              "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
              "      <td>As per your request 'mell mell (oru minnaminun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>spam</td>\n",
              "      <td>WINNER!! As a valued network customer you have...</td>\n",
              "      <td>winner!! As a valu network custom you have bee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spam</td>\n",
              "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
              "      <td>had your mobil 11 month or more? U R entitl to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type  ...                                            stemmed\n",
              "0   ham  ...  Go until jurong point, crazy.. avail onli in b...\n",
              "1   ham  ...                        Ok lar... joke wif u oni...\n",
              "2  spam  ...  free entri in 2 a wkli comp to win FA cup fina...\n",
              "3   ham  ...  U dun say so earli hor... U c alreadi then say...\n",
              "4   ham  ...  nah I don't think he goe to usf, he live aroun...\n",
              "5  spam  ...  freemsg hey there darl it' been 3 week' now an...\n",
              "6   ham  ...  even my brother is not like to speak with me. ...\n",
              "7   ham  ...  As per your request 'mell mell (oru minnaminun...\n",
              "8  spam  ...  winner!! As a valu network custom you have bee...\n",
              "9  spam  ...  had your mobil 11 month or more? U R entitl to...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyPGIgPKklEX",
        "colab_type": "text"
      },
      "source": [
        "Hallamos la matriz de palabras del documento, ignorando aquellas palabras que tengan poca frecuencia (menores a 5) y convertimos todo a minuscula "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-BMv-D3V9CL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "428909f6-bf23-4be3-9d86-7dd5e7d12170"
      },
      "source": [
        "##\n",
        "## Matriz de términos del documento\n",
        "##\n",
        "count_vect = CountVectorizer(\n",
        "    analyzer='word',        # a nivel de palabra\n",
        "    lowercase=True,         # convierte a minúsculas\n",
        "    stop_words='english',   # stop_words en inglés\n",
        "    min_df=5)               # ignora palabras con baja freq\n",
        "\n",
        "##\n",
        "## Aplica la función al texto\n",
        "##\n",
        "df_dtm = count_vect.fit_transform(mails.stemmed)\n",
        "\n",
        "##\n",
        "## Las filas contienen los mensajes\n",
        "## y las clomunas los términos\n",
        "##\n",
        "df_dtm.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5574, 1540)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTi4qx1cnYIs",
        "colab_type": "text"
      },
      "source": [
        "Dividimos nuestros datos en entrenamiento y test, donde x es la matriz de terminos, y Y es la columna \"type\" de mails.\n",
        "Luego aplicamos regresión logistica con cross-validation con LogisticRegressionCV quien aplica Kfold estratificado por default\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpgn4wJBZith",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df_dtm.toarray()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, mails[\"type\"], test_size=0.25)\n",
        "\n",
        "model = LogisticRegressionCV(solver='liblinear', penalty='l1')\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THOI-FFco5kO",
        "colab_type": "text"
      },
      "source": [
        "Ahora, podemos ver que porcentaje de palabras es capaz de acertar nuestro modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZcfXidpaqUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0140bb58-7e00-4f4c-c3fc-3127e2efb416"
      },
      "source": [
        "#accuracy_score(y_test,pred)\n",
        "model.score(X_train,y_train)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99688995215311"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upJgE8dC4S3y",
        "colab_type": "text"
      },
      "source": [
        "Ahora, hagamoslo bajo un modelo de red neuronal con MLPregressor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "939Q-vIYsyfw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y=mails[\"type\"].copy()\n",
        "\n",
        "y=y.replace(\"ham\",0) \n",
        "y=y.replace(\"spam\",1)\n",
        "\n",
        "XX_train, XX_test, yy_train, yy_test = train_test_split(X, y, test_size=0.25)\n",
        "\n",
        "m = sklearn.neural_network.MLPRegressor(\n",
        "                 hidden_layer_sizes = (2,1),  # Una capa oculta con 2 neurona\n",
        "                 activation = 'logistic',    #  {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}\n",
        "                 solver = 'sgd',             #  {‘lbfgs’, ‘sgd’, ‘adam’}\n",
        "                 alpha = 0.0,                #\n",
        "                 learning_rate_init = 0.1,   # Valor de la tasa de aprendizaje\n",
        "                 learning_rate = 'constant', # La tasa no se adapta automáticamente\n",
        "                 verbose = False,            # Reporte del proceso de optimización\n",
        "                 shuffle = True,             #\n",
        "                 tol = 1e-8,                 #\n",
        "                 max_iter = 25000,           # Número máximo de iteraciones\n",
        "                 momentum = 0.0,             #\n",
        "                 nesterovs_momentum = False) #\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdkLpV5z2liD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "b5293995-f025-444d-f812-2fd04d85641e"
      },
      "source": [
        "m.fit(XX_train,yy_train)                                  # Entrena el modelo"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPRegressor(activation='logistic', alpha=0.0, batch_size='auto', beta_1=0.9,\n",
              "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "             hidden_layer_sizes=(2, 1), learning_rate='constant',\n",
              "             learning_rate_init=0.1, max_fun=15000, max_iter=25000,\n",
              "             momentum=0.0, n_iter_no_change=10, nesterovs_momentum=False,\n",
              "             power_t=0.5, random_state=None, shuffle=True, solver='sgd',\n",
              "             tol=1e-08, validation_fraction=0.1, verbose=False,\n",
              "             warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKO9v_mbDsi0",
        "colab_type": "text"
      },
      "source": [
        "Y ahora, veamos que tan bueno es el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-4kj9cvxmB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc682557-b323-4958-bf06-a55e419e7d4c"
      },
      "source": [
        "m.score(XX_test,yy_test)\n",
        "\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.851645417108919"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    }
  ]
}